import os
import sys
import json
import warnings
from os.path import join, getsize
from datetime import datetime, timedelta
from typing import Dict, List
from enum import IntEnum

import __main__
if "DEBUG_MODE" in dir(__main__): DEBUG_MODE = __main__.DEBUG_MODE
else:                             DEBUG_MODE = False

class SRC_TYPE(IntEnum): 
    NATUS = 0
    NEURACLE = 1
    NDRJ = 2
    NEUR_SUB = 3
    NDRJ_SUB = 4
    UNKNOWN = -1

# class OpenWithTimeout(): 
#     ...

# class ScandirWithTimeout(): 
#     ...

from functools import partial
# def OpenWithTimeout(path, mode, *args, **kwargs): 
#     if "b" not in mode: 
#         return open(path, mode, encoding="utf-8", *args, **kwargs)
#     else: 
#         return open(path, mode, *args, **kwargs)

# TODO ä¸‹é¢çš„ä»£ç åªæ˜¯ç®€å•æŠ‘åˆ¶äº†ä»¥ä¸‹æŠ¥é”™ï¼Œå¹¶æ²¡æœ‰å®žçŽ°TimeoutåŠŸèƒ½ï¼Œå¾…å®žçŽ°
ScandirWithTimeout = os.scandir
class OpenWithTimeout:
    def __init__(self, file_name, mode, *args, **kwargs):
        self.file_name = file_name
        self.mode = mode
        self.args = args
        self.kwargs = kwargs
        self.file = None
    def __enter__(self):
        try:
            if "b" not in self.mode:
                self.file = open(self.file_name, self.mode, encoding="utf-8", *(self.args), **(self.kwargs))
            else: 
                self.file = open(self.file_name, self.mode, *(self.args), **(self.kwargs))
            return self.file
        except FileNotFoundError:
            warnings.warn(f"{self.file_name}æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯¥æ•°æ®åŒ…å¯èƒ½å·²ç»æŸåï¼")

    def __exit__(self, exc_type, exc_value, traceback):
        if self.file is not None: self.file.close()
        if exc_type or exc_value or traceback: warnings.warn(f"èŽ·å–{self.file}çš„è¿‡ç¨‹ä¸­å‡ºçŽ°ä»¥ä¸‹é”™è¯¯{exc_type}: {exc_value}]\n{traceback}")
        return True

# OpenWithTimeout = open; ScandirWithTimeout = os.scandir

__all__ = ['SRC_TYPE', 'scan_datadir', 'get_dsize', 'extract_attrs']

class NDRJTreeNode:
    def __init__(self, path):
        self.path = path
        self.children = []
        self.contains_seg = False

def scan_ndrj_patdir(patpath: str, pat_2_path: Dict) -> None: 

    def build_ndrjdb_tree(root_path: str, depth: int=0) -> NDRJTreeNode:
        if depth > 3:
            return None

        node = NDRJTreeNode(root_path)

        topdir = os.path.basename(root_path)
        ndrj_subdir_files = {
            f"{topdir}.eeg", 
            f"{topdir}.ng", 
            f"{topdir}-Seg1-CH1.mp4", 
            f"{topdir}-Seg1-CH1.ref", 
        }
        files_present = set()
        with ScandirWithTimeout(root_path) as entries:
            for entry in entries:
                if entry.is_file():
                    filename = entry.name
                    files_present.add(filename) 
                if entry.is_dir() and depth == 3: # è¿™æ˜¯è¶…ç¦»ä¸‰ç•Œä¹‹å¤–çš„æ–°æ–‡ä»¶å¤¹ï¼Œä¸å¦¨å›žåˆ°åŽŸç‚¹ï¼Œå¼€å§‹å…¨æ–°æ‰«æè¿‡ç¨‹ðŸ˜€
                    scan_datadir(entry.path, pat_2_path)     
        if len(ndrj_subdir_files.intersection(files_present)) > 1: 
            node.contains_seg = len(ndrj_subdir_files.intersection(files_present)) / len(ndrj_subdir_files)

        if depth == 3:
            return node

        for entry in os.scandir(root_path):
            if entry.is_dir():
                child_node = build_ndrjdb_tree(entry.path, depth + 1)
                if child_node is not None:
                    if child_node.contains_seg and not node.contains_seg: node.contains_seg = True
                    node.children.append(child_node)

        return node
    
    root_node = build_ndrjdb_tree(patpath)
    pat_key = os.path.basename(patpath)
    if pat_key not in pat_2_path: pat_2_path[pat_key] = []
    toplist = pat_2_path[pat_key] 

    def generate_info_from_tree(node: NDRJTreeNode, info_list: List) -> None: 
        if not node.contains_seg: scan_datadir(node.path, pat_2_path)
        else: 
            if len(node.children) == 0: 
                info_list.append({
                    "PATH": node.path, 
                    "TYPE": SRC_TYPE.NDRJ.name, 
                    "CONFIDENCE": node.contains_seg, 
                    "SHORTNAME": pat_key[:4] + ".." + pat_key[-4:] if len(pat_key) > 10 else pat_key, 
                })
            else: 
                childs_info_list = []
                info_list.append(childs_info_list)
                for child in node.children: 
                    generate_info_from_tree(child, childs_info_list)

    generate_info_from_tree(root_node, toplist)

ndrj_db_files = {'Eeg.cfg', 'patient.mdb', 'Report.mod'}
neuracle_files = {'datainfo.json', 'evt.bdf', 'ExamInfo.json', 'JsonVersion.json', 'RecordInfo.json', 'videoinfo.json'} 
neuracle_subdir_files = {'data.bdf', 'spike.bdf'}

def scan_datadir(toppath: str, pat_2_path: Dict[str, List[Dict]]) -> None:
    files_present = set()
    global DEBUG_MODE
    if DEBUG_MODE: 
        import time
        start_time = time.time()
    with ScandirWithTimeout(toppath) as entries:
        for entry in entries:
            if entry.is_file():
                filename = entry.name
                files_present.add(filename)  
    if DEBUG_MODE: 
            _dt = time.time() - start_time
            print(f"{toppath}: {_dt:.2f}s", file=sys.stdout if _dt < 0.4 else sys.stderr)
    topdir = os.path.basename(toppath)  
    natus_files = {
        f"{topdir}.eeg", 
        f"{topdir}.ent", 
        f"{topdir}.epo", 
        f"{topdir}.erd", 
        f"{topdir}.etc", 
        f"{topdir}.snc", 
        f"{topdir}.stc", 
        f"{topdir}.vtc", 
        f"{topdir}.vt2", 
    }
    ndrj_subdir_files = {
        f"{topdir}.eeg", 
        f"{topdir}.ng", 
        f"{topdir}-Seg1-CH1.mp4", 
        f"{topdir}-Seg1-CH1.ref", 
    }    
    if len(natus_files.intersection(files_present)) > 1: 
        # æˆªå–åç§°ä¸­_ä¹‹å‰çš„éƒ¨åˆ†ä½œä¸ºpat_key
        if (_loc := topdir.find('_')) != -1 and (_loc + 1 + 36) == len(topdir): 
                pat_key = topdir[:_loc]
        else:   pat_key = topdir

        video_lst = list(filter(lambda fn: fn.endswith(".avi"), files_present)); video_lst.sort()

        this_elem = {
            "PATH": toppath, 
            "TYPE": SRC_TYPE.NATUS.name, 
            "CONFIDENCE": len(natus_files.intersection(files_present)) / len(natus_files),  
            "SHORTNAME": topdir[:4] + ".." + topdir[-4:] if len(topdir) > 10 else topdir, 
        }
        if len(video_lst) > 0: this_elem["video_lst"] = video_lst
        if pat_key in pat_2_path: pat_2_path[pat_key].append(this_elem)
        else: pat_2_path[pat_key] = [this_elem]

        with os.scandir(toppath) as entries: # ä¹‹å‰å·²ç»æˆåŠŸåœ¨æœ‰é™æ—¶é—´å†…è¯»å–ï¼Œæ­¤å¤„å¯ä»¥ç”¨æ™®é€šscandir
            for entry in entries:
                if entry.is_dir() and entry.name != "Decimated":
                    scan_datadir(entry.path, pat_2_path)                        
    
    elif len(neuracle_files.intersection(files_present)) > 1: 
        content = None # æ‚£è€…åå­—å’Œå¼€å§‹æ—¶é—´
        with OpenWithTimeout(join(toppath, "ExamInfo.json"), "rt") as f: 
            content = f.read()
        
        examinfo = dict(); this_elem = dict()
        try: 
            examinfo = json.loads(content)
        except Exception as err: 
            warnings.warn(f"è§£æž{join(toppath, 'ExamInfo.json')}æ—¶å‡ºé”™ï¼Œæ•°æ®åŒ…å¯èƒ½å·²ç»æŸåï¼")
            this_elem["BROKEN"] = True
        
        pat_key = examinfo["FullName"] if "FullName" in examinfo else topdir
        
        if "FullName" not in examinfo:  
            warnings.warn(f"{join(toppath, 'ExamInfo.json')}ç¼ºé”®ï¼Œæ•°æ®åŒ…å¯èƒ½å·²ç»æŸåï¼")
            this_elem["BROKEN"] = True
        if "ExamTime" in examinfo: 
            # this_elem['è®°å½•æ—¶é—´'] = examinfo["ExamTime"] 
            this_elem['start_dt'] = datetime.fromisoformat(examinfo["ExamTime"])
        else: 
            warnings.warn(f"{join(toppath, 'ExamInfo.json')}ç¼ºé”®ï¼Œæ•°æ®åŒ…å¯èƒ½å·²ç»æŸåï¼")
            this_elem["BROKEN"] = True

        this_elem.update({
            "PATH": toppath, 
            "TYPE": SRC_TYPE.NEURACLE.name, 
            "CONFIDENCE": len(neuracle_files.intersection(files_present)) / len(neuracle_files), 
            "SHORTNAME": topdir[:4] + ".." + topdir[-4:] if len(topdir) > 10 else topdir, 
        })
        
        if pat_key in pat_2_path: pat_2_path[pat_key].append(this_elem)
        else: pat_2_path[pat_key] = [this_elem]                
        
        # æ‰«æå­æ–‡ä»¶å¤¹å¹¶èŽ·å–å¯èƒ½å­˜åœ¨çš„è§†é¢‘è·¯å¾„åˆ—è¡¨
        
        with os.scandir(toppath) as entries: # ä¹‹å‰å·²ç»æˆåŠŸåœ¨æœ‰é™æ—¶é—´å†…è¯»å–ï¼Œæ­¤å¤„å¯ä»¥ç”¨æ™®é€šscandir
            for entry in entries:
                if entry.is_dir():
                    bdf_count = 0; video_lst = []; to_be_scaned_lst = []
                    with ScandirWithTimeout(entry.path) as subents: 
                        for sub_entry in subents:
                            if sub_entry.is_dir(): to_be_scaned_lst.append(sub_entry.path)
                            elif sub_entry.is_file(): 
                                if sub_entry.name in neuracle_subdir_files: bdf_count += 1
                                if sub_entry.name.endswith('avi'): video_lst.append(os.path.relpath(sub_entry.path, start=toppath))
                    if bdf_count == 0: scan_datadir(entry.path, pat_2_path) 
                    else: 
                        if bdf_count == 1: this_elem["BROKEN"] = True
                        if "video_lst" in this_elem: 
                            this_elem["video_lst"] += video_lst  
                        elif video_lst: 
                            this_elem["video_lst"] = video_lst
                        for unrecognized_subpath in to_be_scaned_lst:
                            scan_datadir(unrecognized_subpath, pat_2_path)
        if "video_lst" in this_elem: this_elem["video_lst"].sort()

    elif len(ndrj_db_files.intersection(files_present)) > 1: 
        with os.scandir(toppath) as entries: # ä¹‹å‰å·²ç»æˆåŠŸåœ¨æœ‰é™æ—¶é—´å†…è¯»å–ï¼Œæ­¤å¤„å¯ä»¥ç”¨æ™®é€šscandir
            for pat in entries:
                if pat.is_dir():
                    scan_ndrj_patdir(pat.path, pat_2_path)
    
    elif len(neuracle_subdir_files.intersection(files_present)) > 1: # åšç¿åº·ä¸å®Œæ•´æ•°æ®åŒ…
        pat_key = topdir

        video_lst = list(filter(lambda fn: fn.endswith(".avi"), files_present)); video_lst.sort()

        this_elem = {
            "PATH": toppath, 
            "TYPE": SRC_TYPE.NEUR_SUB.name, 
            "CONFIDENCE": len(neuracle_subdir_files.intersection(files_present)) / len(natus_files), 
            "SHORTNAME": topdir[:4] + ".." + topdir[-4:] if len(topdir) > 10 else topdir, 
        }     
        if len(video_lst) > 0: this_elem["video_lst"] = video_lst
        if pat_key in pat_2_path: pat_2_path[pat_key].append(this_elem)
        else: pat_2_path[pat_key] = [this_elem]

        with os.scandir(toppath) as entries: # ä¹‹å‰å·²ç»æˆåŠŸåœ¨æœ‰é™æ—¶é—´å†…è¯»å–ï¼Œæ­¤å¤„å¯ä»¥ç”¨æ™®é€šscandir
            for entry in entries:
                if entry.is_dir():
                    scan_datadir(entry.path, pat_2_path)    
    
    elif len(ndrj_subdir_files.intersection(files_present)) > 1: 
        pat_key = topdir

        this_elem = {
            "PATH": toppath, 
            "TYPE": SRC_TYPE.NDRJ_SUB.name, 
            "CONFIDENCE": len(ndrj_subdir_files.intersection(files_present)) / len(natus_files), 
            "SHORTNAME": topdir[:4] + ".." + topdir[-4:] if len(topdir) > 10 else topdir, 
        }     

        if pat_key in pat_2_path: pat_2_path[pat_key].append(this_elem)
        else: pat_2_path[pat_key] = [this_elem]

        with os.scandir(toppath) as entries: # ä¹‹å‰å·²ç»æˆåŠŸåœ¨æœ‰é™æ—¶é—´å†…è¯»å–ï¼Œæ­¤å¤„å¯ä»¥ç”¨æ™®é€šscandir
            for entry in entries:
                if entry.is_dir():
                    scan_datadir(entry.path, pat_2_path)  
    
    else: 
        with os.scandir(toppath) as entries: # ä¹‹å‰å·²ç»æˆåŠŸåœ¨æœ‰é™æ—¶é—´å†…è¯»å–ï¼Œæ­¤å¤„å¯ä»¥ç”¨æ™®é€šscandir
            for entry in entries:
                if entry.is_dir():
                    scan_datadir(entry.path, pat_2_path)          

# ç»Ÿè®¡åŒ…å«eegçš„æ–‡ä»¶å¤¹åŠå…¶å­æ–‡ä»¶å¤¹å ç”¨ç©ºé—´çš„å¤§å°
# TODO å¯èƒ½è€—æ—¶ä¸”å¯èƒ½å› ä¸ºè½¯ç¡¬ä»¶é”™è¯¯å¡æ­»ï¼Œæ”¹ä¸ºæ”¯æŒå–æ¶ˆçš„å¼‚æ­¥ç¼–ç¨‹æˆ–è€…å¤šçº¿ç¨‹ç¼–ç¨‹
def get_dsize(toppath: str) -> int:
    ans = 0
    for root, dirs, files in os.walk(toppath):
        for name in files:
            ans += getsize(join(root, name))
    return ans                

features = [
              b'"FirstName"', 
              b'"LastName"', 
              b'"MiddleName"', 
              b'"PatientGUID"', 
              b'"CreationTime"', 
              b'"StudyName"', 
              b'"StudyRecordTime"'
            ]

### [Deprecated] ä½¿ç”¨æ ‡å‡†æ ¼å¼æ›´å¥½ï¼
# # extract_natus_attrs()ä¼šç”¨åˆ°çš„è¾…åŠ©å‡½æ•°ï¼Œæ—¥æœŸæ ¼å¼è½¬æ¢
# def _get_ct_str(ctime: float) -> str:
#     td = timedelta(days=ctime)
#     dt = datetime(1899, 12, 30) + td
#     return '%4då¹´%2dæœˆ%2dæ—¥%2dæ—¶%2dåˆ†%2dç§’' % (dt.year, dt.month, dt.day, 
#                                              dt.hour, dt.minute, dt.second)

# # extract_natus_attrs()ä¼šç”¨åˆ°çš„è¾…åŠ©å‡½æ•°ï¼Œæ—¶é—´æ ¼å¼è½¬æ¢
# def _get_srt_str(srtime: float) -> str:
#     srsec = round(srtime)
#     return '%2dæ—¶%2dåˆ†%2dç§’' % (srsec // 3600, srsec % 3600 // 60, srsec % 60)

def extract_bebug_timer(func): 
    global DEBUG_MODE
    if DEBUG_MODE: 
        import time
        def wrapper(dirpath: str): 
            _t0 = time.time()
            res = func(dirpath)
            _dt = time.time() - _t0
            print(f"{dirpath}: {_dt:.2f}s", file=sys.stdout if _dt < 0.4 else sys.stderr)
            return res
        return wrapper
    else: 
        return func

import re
# ä»Žeegæ–‡ä»¶çš„å†…å®¹ä¸­æå–å‡ºä¸€ä¸ªdictï¼ŒåŒ…å«æ‚£è€…å§“åã€è®°å½•æ—¶é—´ã€æŒç»­æ—¶é—´ç­‰ä¿¡æ¯
# ä»Žentæ–‡ä»¶ç§æå–å‡ºæ‰€æœ‰çŽ°å­˜æ ‡æ³¨
### TODO è¿™é‡Œå¥½å¥½ä½¿ç”¨ç»“æž„åŒ–ç¼–ç¨‹æŠ€æœ¯é‡æž„æˆå¼‚å¸¸å®‰å…¨çš„ï¼ï¼ï¼
@extract_bebug_timer
def extract_natus_attrs(dirpath: str) -> Dict:
    eegfile = join(dirpath, os.path.basename(dirpath)+".eeg")
    val = dict()

    content = None
    with OpenWithTimeout(eegfile, "rb") as f: 
        content = f.read()
    if content is None: 
        warnings.warn(f"æ— æ³•è¯»å–EEGæ–‡ä»¶{eegfile}")
        val["BROKEN"] = True        
    else: 
        for name in features:
            if name.endswith(b'Time"'): # CreationTime, StudyRecordTime çš„å€¼æ˜¯æ•°å€¼åž‹
                pattern = re.compile(rb'\.' + name + rb'\s*,\s*([0-9\.]+)')
                match = pattern.search(content)
                if match:
                    val[name] = float(match.group(1))
                else: 
                    warnings.warn(f"æ— æ³•ä»ŽEEGæ–‡ä»¶{eegfile}ä¸­æ‰¾åˆ°ç‰¹å¾{name}")
                    val["BROKEN"] = True
            else: # å…¶ä»–å±žæ€§æ˜¯å­—ç¬¦ä¸²åž‹ï¼Œæœ‰å¼•å·åŒ…å›´
                pattern = re.compile(rb'\.' + name + rb'\s*,\s*"([^"]*)"')
                match = pattern.search(content)
                if match:
                    val[name] = match.group(1)
                else: 
                    warnings.warn(f"æ— æ³•ä»ŽEEGæ–‡ä»¶{eegfile}ä¸­æ‰¾åˆ°ç‰¹å¾{name}")  
                    val["BROKEN"] = True                                      

    # patient = str(val[b'"FirstName"'] + val[b'"MiddleName"'] + val[b'"LastName"'], 
    #               encoding='ascii'  )
    ret =   {
            #   'æ‚£è€…å§“å': patient, 
            #   'PGUID': str(val[b'"PatientGUID"'], encoding='ascii'), 
            #   'è®°å½•æ—¶é—´': _get_ct_str(val[b'"CreationTime"']), 
            #   'CTime': val[b'"CreationTime"'], 
            #   'æŒç»­æ—¶é—´': _get_srt_str(val[b'"StudyRecordTime"']), 
            #   'SRTime': val[b'"StudyRecordTime"'],
              'è®°å½•åç§°': str(val[b'"StudyName"'], encoding='ascii') if b'"StudyName"' in val else '',
              **val
            }
    
    if b'"CreationTime"' in val: 
              ret['start_dt'] = datetime(1899, 12, 30) + timedelta(days=val[b'"CreationTime"']) 
    if b'"StudyRecordTime"' in val: 
              ret['timedelta'] = timedelta(seconds=val[b'"StudyRecordTime"'])     

    content = None # æå–æ³¨é‡Šä¿¡æ¯
    entfile = eegfile[:-3]+"ent"
    with OpenWithTimeout(entfile, 'rb') as f:
        content = f.read()
    
    if content is not None: 
        pattern = rb'\(\."Stamp", ([0-9]*)\), \(\."Text", "([^"]*)"\), \(\."Type", "([^"]*)"\)' 
        # ä¾‹å¦‚è¿™ä¸ª(."Stamp", 2294), (."Text", "Montage:Cui_YiBing"), (."Type", "Annotation")
        matches = re.findall(pattern, content)

        if len(matches) > 0: ret["annotations"] = matches
    else: 
        warnings.warn(f"æ— æ³•è¯»å–{entfile}")
        ret["BROKEN"] = True

    return ret

@extract_bebug_timer
def extract_neuracle_attrs(dirpath: str) -> Dict: 
    ret = dict()
    content = None # æå–è®°å½•æŒç»­æ—¶é—´
    with OpenWithTimeout(join(dirpath, "datainfo.json"), "rt") as f: 
        content = f.read()
    datainfo = dict()
    try: 
        datainfo = json.loads(content)
    except Exception as err: 
        warnings.warn(f"è§£æž{join(dirpath, 'datainfo.json')}æ—¶å‡ºé”™ï¼Œæ•°æ®åŒ…å¯èƒ½å·²ç»æŸåï¼")
        ret["BROKEN"] = True
    
    if "duration" in datainfo: 
        ret['timedelta'] = timedelta(seconds=datainfo["duration"])
    else: 
        warnings.warn(f"{join(dirpath, 'datainfo.json')}ç¼ºé”®ï¼Œæ•°æ®åŒ…å¯èƒ½å·²ç»æŸåï¼")
        ret["BROKEN"] = True
    
    try: 
        from robust_io import EdfReaderContextManager
    except ImportError: 
        warnings.warn(f"è§£æžåšç¿åº·æ•°æ®æ³¨é‡Šéœ€è¦pyedflibï¼Œæœªèƒ½æ£€æµ‹åˆ°æ”¹ä¸ºä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
        content = None # æå–æ³¨é‡Š
        with OpenWithTimeout(join(dirpath, "RecordInfo.json"), "rt") as f: 
            content = f.read()
        RecordInfo = dict()
        try: 
            RecordInfo = json.loads(content)
        except Exception as err: 
            warnings.warn(f"è§£æž{join(dirpath, 'RecordInfo.json')}æ—¶å‡ºé”™ï¼Œæ•°æ®åŒ…å¯èƒ½å·²ç»æŸåï¼")
            ret["BROKEN"] = True
        
        if "RecordEvents" in RecordInfo: 
            ret['annotations'] = RecordInfo["RecordEvents"]
        else: 
            warnings.warn(f"{join(dirpath, 'RecordInfo.json')}ç¼ºé”®ï¼Œæ•°æ®åŒ…å¯èƒ½å·²ç»æŸåï¼")
            ret["BROKEN"] = True        
    else: 
        # å½“ sys.getdefaultencoding() ä¸æ˜¯ utf-8 æ—¶ï¼Œpyedflib æœ‰ bugï¼Œä¸»è¦åœ¨ Windows å¹³å°
        # import contextlib
        # with contextlib.redirect_stdout(None), contextlib.redirect_stderr(None):
        #     with contextlib.suppress():      
                with EdfReaderContextManager(join(dirpath, "evt.bdf")) as edf_reader: # å½“è¿™é‡Œå‡ºé”™æ—¶åº”è¯¥ä¹Ÿè¦å›žé€€åˆ°é™çº§æŽªæ–½ï¼
                    if edf_reader is not None:
                        # èŽ·å–æ³¨é‡Šä¿¡æ¯
                        annotations = edf_reader.readAnnotations()
                        annt_lst = []

                        for i in range(len(annotations[0])):
                            onset = annotations[0][i]
                            duration = annotations[1][i]
                            description = annotations[2][i]
                            annt_lst.append(f"Onset: {onset}  Duration: {duration}  Description: {description}")
                        
                        ret["annotations"] = annt_lst 

    return ret

@extract_bebug_timer
def extract_ndrj_attrs(dirpath: str) -> Dict: 
    return dict()

def _default_extract_attrs(dirpath: str) -> Dict: 
    return dict()

extract_attrs = {
    SRC_TYPE.NATUS.name: extract_natus_attrs, 
    SRC_TYPE.NEURACLE.name: extract_neuracle_attrs, 
    SRC_TYPE.NDRJ.name: extract_ndrj_attrs, 
    SRC_TYPE.NEUR_SUB.name: _default_extract_attrs, 
    SRC_TYPE.NDRJ_SUB.name: _default_extract_attrs, 
    SRC_TYPE.UNKNOWN.name: _default_extract_attrs
}