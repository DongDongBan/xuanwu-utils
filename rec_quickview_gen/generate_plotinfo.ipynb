{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyedflib import EdfReader\n",
    "\n",
    "class EdfReaderWrapper(EdfReader):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    def __exit__(self, *args):\n",
    "        super().close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "outdir = \"./chbmit-plotinfo\"\n",
    "data_dir = \"/home/zgl/publicdata/CHBMIT/0_data_edf/chbmit/1.0.0\"\n",
    "ignore_lst = [\"chb16_18.edf\", \"chb16_19.edf\", \"chb17c_13.edf\", \"chb18_01.edf\", \"chb19_01.edf\", \"chb11_01.edf\", \"chb12_27.edf\", \"chb12_28.edf\", \"chb12_29.edf\", \"chb09_01.edf\", \"chb15_01.edf\"]\n",
    "\n",
    "# TODO 改为上面的isoformat\n",
    "dt_fmt = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "for indexPatient in range(1, 24+1):\n",
    "    result_obj = {\"record_lst\": [], \"seizure_lst\": [], \"unused_rec_idx_lst\": []}\n",
    "    with open(os.path.join(data_dir, f\"chb{indexPatient:02d}\", f\"chb{indexPatient:02d}-summary.txt\"), 'r') as f:\n",
    "        for line in f:\n",
    "            data=line.split(':')\n",
    "            if(data[0]==\"File Name\"):\n",
    "                edfName=data[1].strip()\n",
    "\n",
    "                with EdfReaderWrapper(os.path.join(data_dir, f\"chb{indexPatient:02d}\", edfName)) as pedf: \n",
    "                    startTime = pedf.getStartdatetime()\n",
    "                    startStr = startTime.isoformat()\n",
    "                    endTime = startTime + datetime.timedelta(seconds=pedf.getFileDuration())\n",
    "                    endStr = endTime.isoformat()\n",
    "                    result_obj[\"record_lst\"].append({\n",
    "                        \"file\": edfName, \n",
    "                        \"span\": [startStr, endStr], \n",
    "                        \"info\": f\"edfName records {startTime} ~ {endTime} \\r\\n of shape {pedf.signals_in_file, pedf.getNSamples()[0]}\"\n",
    "                    })\n",
    "                    \n",
    "                nextLine = f.readline().strip()\n",
    "                while (len(nextLine) != 0 and not nextLine.startswith('Number of Seizures in File:')):\n",
    "                    nextLine = f.readline().strip()\n",
    "                if nextLine.startswith('Number of Seizures in File:'):\n",
    "                    for j in range(0, int(nextLine.split(':')[1])):\n",
    "                        szStartSec = int(f.readline().split(': ')[1].strip().split(' ')[0])\n",
    "                        szEndSec = int(f.readline().split(': ')[1].strip().split(' ')[0])\n",
    "                        result_obj[\"seizure_lst\"].append({\n",
    "                            \"span\": [startTime+timedelta(seconds=szStartSec), startTime+timedelta(seconds=szEndSec)], \n",
    "                            \"info\": f'Onset {startTime+timedelta(seconds=szStartSec)}, last {szEndSec - szStartSec}s'\n",
    "                        })\n",
    "\n",
    "        # result_obj[\"record_lst\"].sort(key=lambda obj:obj[\"span\"])\n",
    "        # result_obj[\"seizure_lst\"].sort(key=lambda obj:obj[\"span\"])\n",
    "        for k, rec_info in enumerate(result_obj[\"record_lst\"]):\n",
    "            if rec_info[\"file\"] in ignore_lst:\n",
    "                result_obj[\"unused_rec_idx_lst\"].append(k)\n",
    "        #   rec_info[\"span\"] = [rec_info[\"span\"][0].isoformat(), rec_info[\"span\"][1].isoformat()]\n",
    "        \n",
    "    with open(os.path.join(outdir, f'chb{indexPatient:02d}.json'), 'wt') as f:\n",
    "        json.dump(result_obj, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "\n",
    "class MNEEdfObjWrapper:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.raw = mne.io.read_raw_edf(*args, **kwargs)\n",
    "    def __enter__(self):\n",
    "        return self.raw\n",
    "    def __exit__(self, *args):\n",
    "        self.raw.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "# TODO 添加对Offset注释的识别\n",
    "def _is_possile_sz(s: str, kws: List[str] = ['sz', 'seiz', 'onset', '发作', '癫痫']): \n",
    "    s = s.lower()\n",
    "    if any([ kw in s for kw in kws ]):  return True\n",
    "    else:                               return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "xuanwu_data_path = \"/mnt/share/data/xuanwu_raw_merged/cuiyibing/\"\n",
    "plot_args_path = \"./cui-mneinfo/\"; os.makedirs(plot_args_path, exist_ok=True)\n",
    "ignore_lst = []\n",
    "\n",
    "import os\n",
    "import json, csv\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "\n",
    "with os.scandir(xuanwu_data_path) as entries:\n",
    "    for entry in entries:\n",
    "                        result_obj = {\"record_lst\": [], \"seizure_lst\": [], \"unused_rec_idx_lst\": []}\n",
    "                        record_fn_lst =  glob.glob(os.path.join(entry.path, \"**\", \"*.edf\"), recursive=True)\n",
    "                        record_fn_lst.extend(glob.glob(os.path.join(entry.path, \"**\", \"*.EDF\"), recursive=True))\n",
    "                        record_fn_lst.extend(glob.glob(os.path.join(entry.path, \"**\", \"*.BDF\"), recursive=True))\n",
    "                        record_fn_lst.extend(glob.glob(os.path.join(entry.path, \"**\", \"*.bdf\"), recursive=True))\n",
    "                        \n",
    "                        last_ch_names = None\n",
    "                        for edf_path in record_fn_lst:\n",
    "                            try:\n",
    "                                print(f\"Try loading {edf_path}\")\n",
    "                                # with EdfReaderWrapper(edf_path) as pedf:\n",
    "                                #     start_dt = pedf.getStartdatetime()\n",
    "                                #     end_dt = start_dt + timedelta(seconds=(edf_len := pedf.getFileDuration()))\n",
    "                                #     fs = pedf.getSampleFrequency(0)\n",
    "                                #     # assert all((FS := pedf.getSampleFrequencies()) == fs) # TODO 支持过滤非脑电数据通道\n",
    "                                #     result_obj[\"record_lst\"].append({\n",
    "                                #         \"file\": os.path.basename(edf_path), \n",
    "                                #         # \"span\": [start_dt.isoformat(), end_dt.isoformat()], \n",
    "                                #         \"span\": [start_dt, end_dt], \n",
    "                                #         \"info\": f\"{os.path.basename(edf_path)} of shape {pedf.signals_in_file, pedf.getNSamples()[0]}\"\n",
    "                                #     })\n",
    "                                with MNEEdfObjWrapper(edf_path, preload=False) as raw:\n",
    "                                    start_dt = raw.info['meas_date']\n",
    "                                    end_dt = start_dt + timedelta(seconds=(raw.n_times / raw.info['sfreq'])) # TODO 核查对于EDF-D情形下此算法是否正确\n",
    "                                    fs = raw.info['sfreq']\n",
    "\n",
    "                                    # 构建病人信息字典，并添加到列表中\n",
    "                                    result_obj[\"record_lst\"].append({\n",
    "                                        \"file\": os.path.basename(edf_path),\n",
    "                                        \"span\": [start_dt, end_dt],\n",
    "                                        \"info\": f\"{os.path.basename(edf_path)} of shape {len(raw.ch_names), raw.n_times}\", \n",
    "                                        \"annotations\": [(a['onset'], a['description']) for a in raw.annotations] if hasattr(raw, 'annotations') else []\n",
    "                                    })   \n",
    "                                    \n",
    "                                    # 检查跨文件通道一致性\n",
    "                                    if last_ch_names is None: last_ch_names = raw.ch_names\n",
    "                                    elif last_ch_names != raw.ch_names: \n",
    "                                        warnings.warn(f\"相较于之前的通道排布发生变化！\\n{edf_path}\")\n",
    "                                        last_ch_names = raw.ch_names\n",
    "\n",
    "                                    # TODO 非精准匹配可能的发作标注\n",
    "                                    for annt in raw.annotations: \n",
    "                                        if _is_possile_sz(annt['description']): \n",
    "                                            result_obj[\"seizure_lst\"].append({\n",
    "                                                \"span\": [annt['orig_time'], annt['orig_time']+timedelta(seconds=annt['duration'])], \n",
    "                                                \"info\": f\"Onset {annt['orig_time'].isoformat()}, last {annt['duration']}s\"\n",
    "                                            })\n",
    "                                                                     \n",
    "                            except ValueError as exp:\n",
    "                                warnings.warn(f\"ValueError from {exp}\")\n",
    "\n",
    "                        result_obj[\"record_lst\"].sort(key=lambda obj:obj[\"span\"])\n",
    "                        result_obj[\"seizure_lst\"].sort(key=lambda obj:obj[\"span\"])\n",
    "                        for k, rec_info in enumerate(result_obj[\"record_lst\"]):\n",
    "                            if rec_info[\"file\"] in ignore_lst:\n",
    "                                result_obj[\"unused_rec_idx_lst\"].append(k)\n",
    "                            rec_info[\"span\"] = [rec_info[\"span\"][0].isoformat(), rec_info[\"span\"][1].isoformat()]\n",
    "                        \n",
    "                        for seiz_info in result_obj[\"seizure_lst\"]:\n",
    "                            seiz_info[\"span\"] = [seiz_info[\"span\"][0].isoformat(), seiz_info[\"span\"][1].isoformat()]\n",
    "                            \n",
    "                        with open(os.path.join(plot_args_path, f'{entry.name}.json'), \"wt\") as fout:\n",
    "                            json.dump(result_obj, fout, indent=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./cui-mneinfo/cuiyibing_converted.json\", \"rt\") as f:\n",
    "    result_obj = json.load(f)\n",
    "\n",
    "for k, rec_info in enumerate(result_obj[\"record_lst\"]):\n",
    "    # if rec_info[\"file\"] in ignore_lst:\n",
    "    #     result_obj[\"unused_rec_idx_lst\"].append(k)\n",
    "    rec_info[\"span\"] = [datetime.fromisoformat(rec_info[\"span\"][0]), datetime.fromisoformat(rec_info[\"span\"][1])]\n",
    "\n",
    "for seiz_info in result_obj[\"seizure_lst\"]:\n",
    "    seiz_info[\"span\"] = [datetime.fromisoformat(seiz_info[\"span\"][0]), datetime.fromisoformat(seiz_info[\"span\"][1])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as pyo\n",
    "from timeline import get_pat_timeline\n",
    "fig = get_pat_timeline(title=\"Cui YiBing\", record_seq=result_obj[\"record_lst\"], seizure_seq=result_obj[\"seizure_lst\"])\n",
    "\n",
    "pyo.plot(fig, filename=\"./cui-mneinfo/cui-timeline.html\", # include_plotlyjs=\"./plotly.min.js\", \n",
    "            auto_open=False, image='svg', image_width=2560, image_height=1440)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
